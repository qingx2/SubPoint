"""
AI æ€»ç»“æ¨¡å—
ä½¿ç”¨ OpenAI API å¯¹å†…å®¹è¿›è¡Œæ€»ç»“
"""
from pathlib import Path
from typing import Optional
from rich.console import Console
from rich.markdown import Markdown
from openai import OpenAI

from config import OPENAI_API_KEY, OPENAI_BASE_URL, OPENAI_MODEL, OUTPUT_DIR

console = Console()

# æ€»ç»“æç¤ºè¯æ¨¡æ¿
SUMMARY_PROMPT_ZH = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹æ€»ç»“ä¸“å®¶ã€‚è¯·å¯¹ä»¥ä¸‹å†…å®¹è¿›è¡Œå…¨é¢åˆ†æå’Œæ€»ç»“ã€‚

**è¦æ±‚ï¼š**
1. é¦–å…ˆæä¾›ä¸€ä¸ªç®€æ´çš„æ‘˜è¦ï¼ˆ2-3å¥è¯ï¼‰
2. åˆ—å‡ºæ ¸å¿ƒè¦ç‚¹ï¼ˆä½¿ç”¨é¡¹ç›®ç¬¦å·ï¼‰
3. æå–å…³é”®ä¿¡æ¯å’Œé‡è¦æ•°æ®
4. å¦‚æœæœ‰çš„è¯ï¼Œæ€»ç»“ä¸»è¦è§‚ç‚¹å’Œç»“è®º
5. æ ‡æ³¨ä»»ä½•è¡ŒåŠ¨é¡¹æˆ–å»ºè®®

**è¾“å‡ºæ ¼å¼ï¼š**
# å†…å®¹æ€»ç»“

## ğŸ“Œ æ‘˜è¦
[ç®€æ´çš„å†…å®¹æ¦‚è¿°]

## ğŸ¯ æ ¸å¿ƒè¦ç‚¹
- [è¦ç‚¹1]
- [è¦ç‚¹2]
- ...

## ğŸ’¡ å…³é”®ä¿¡æ¯
[é‡è¦çš„æ•°æ®ã€äº‹å®ã€å¼•ç”¨ç­‰]

## ğŸ“ ä¸»è¦è§‚ç‚¹
[ä¸»è¦è®ºç‚¹å’Œç»“è®º]

## âœ… è¡ŒåŠ¨å»ºè®®ï¼ˆå¦‚é€‚ç”¨ï¼‰
[å¯æ‰§è¡Œçš„å»ºè®®æˆ–ä¸‹ä¸€æ­¥]

---

**ä»¥ä¸‹æ˜¯éœ€è¦æ€»ç»“çš„å†…å®¹ï¼š**

{content}
"""

SUMMARY_PROMPT_EN = """You are a professional content summarizer. Please analyze and summarize the following content comprehensively.

**Requirements:**
1. Provide a brief summary (2-3 sentences)
2. List key points (using bullet points)
3. Extract important information and data
4. Summarize main arguments and conclusions if any
5. Note any action items or recommendations

**Output Format:**
# Content Summary

## ğŸ“Œ Summary
[Brief overview of the content]

## ğŸ¯ Key Points
- [Point 1]
- [Point 2]
- ...

## ğŸ’¡ Key Information
[Important data, facts, quotes, etc.]

## ğŸ“ Main Arguments
[Main arguments and conclusions]

## âœ… Action Items (if applicable)
[Actionable recommendations or next steps]

---

**Content to summarize:**

{content}
"""


def get_client() -> OpenAI:
    """è·å– OpenAI å®¢æˆ·ç«¯"""
    if not OPENAI_API_KEY:
        raise ValueError("OPENAI_API_KEY æœªè®¾ç½®ï¼Œè¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½®")
    
    return OpenAI(
        api_key=OPENAI_API_KEY,
        base_url=OPENAI_BASE_URL if OPENAI_BASE_URL else None,
    )


def summarize_text(
    text: str,
    language: str = "zh",
    model: Optional[str] = None,
    custom_prompt: Optional[str] = None,
) -> str:
    """
    ä½¿ç”¨ AI æ€»ç»“æ–‡æœ¬å†…å®¹
    
    Args:
        text: è¦æ€»ç»“çš„æ–‡æœ¬
        language: è¾“å‡ºè¯­è¨€ ('zh' æˆ– 'en')
        model: ä½¿ç”¨çš„æ¨¡å‹
        custom_prompt: è‡ªå®šä¹‰æç¤ºè¯
    
    Returns:
        æ€»ç»“ç»“æœ
    """
    client = get_client()
    model = model or OPENAI_MODEL
    
    # é€‰æ‹©æç¤ºè¯
    if custom_prompt:
        prompt = custom_prompt.format(content=text)
    else:
        prompt_template = SUMMARY_PROMPT_ZH if language == "zh" else SUMMARY_PROMPT_EN
        prompt = prompt_template.format(content=text)
    
    # å¦‚æœæ–‡æœ¬å¤ªé•¿ï¼Œè¿›è¡Œåˆ†å—å¤„ç†
    max_chars = 100000  # å¤§çº¦ 25000 tokens
    if len(text) > max_chars:
        console.print("[yellow]âš ï¸  å†…å®¹è¾ƒé•¿ï¼Œå°†è¿›è¡Œåˆ†å—æ€»ç»“[/yellow]")
        return summarize_long_text(text, language, model)
    
    console.print(f"[yellow]ğŸ¤– æ­£åœ¨ä½¿ç”¨ {model} ç”Ÿæˆæ€»ç»“...[/yellow]")
    
    response = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹åˆ†æå’Œæ€»ç»“ä¸“å®¶ã€‚"},
            {"role": "user", "content": prompt},
        ],
        temperature=0.3,
    )
    
    return response.choices[0].message.content


def summarize_long_text(
    text: str,
    language: str = "zh",
    model: Optional[str] = None,
    chunk_size: int = 80000,
) -> str:
    """
    åˆ†å—æ€»ç»“é•¿æ–‡æœ¬
    """
    client = get_client()
    model = model or OPENAI_MODEL
    
    # åˆ†å—
    chunks = []
    for i in range(0, len(text), chunk_size):
        chunks.append(text[i:i + chunk_size])
    
    console.print(f"[cyan]ğŸ“š åˆ†æˆ {len(chunks)} ä¸ªéƒ¨åˆ†è¿›è¡Œæ€»ç»“[/cyan]")
    
    # åˆ†åˆ«æ€»ç»“æ¯ä¸ªéƒ¨åˆ†
    chunk_summaries = []
    for i, chunk in enumerate(chunks, 1):
        console.print(f"[yellow]ğŸ”„ æ€»ç»“ç¬¬ {i}/{len(chunks)} éƒ¨åˆ†...[/yellow]")
        
        prompt = f"è¯·ç®€æ´æ€»ç»“ä»¥ä¸‹å†…å®¹çš„è¦ç‚¹ï¼š\n\n{chunk}"
        
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹æ€»ç»“ä¸“å®¶ã€‚è¯·æä¾›ç®€æ´çš„è¦ç‚¹æ€»ç»“ã€‚"},
                {"role": "user", "content": prompt},
            ],
            temperature=0.3,
        )
        chunk_summaries.append(response.choices[0].message.content)
    
    # åˆå¹¶æ€»ç»“
    console.print("[yellow]ğŸ”„ åˆå¹¶æ‰€æœ‰éƒ¨åˆ†çš„æ€»ç»“...[/yellow]")
    
    combined = "\n\n---\n\n".join([f"**ç¬¬{i}éƒ¨åˆ†æ€»ç»“:**\n{s}" for i, s in enumerate(chunk_summaries, 1)])
    
    final_prompt = SUMMARY_PROMPT_ZH if language == "zh" else SUMMARY_PROMPT_EN
    final_prompt = final_prompt.format(content=combined)
    
    response = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹åˆ†æå’Œæ€»ç»“ä¸“å®¶ã€‚ä»¥ä¸‹æ˜¯åˆ†æ®µæ€»ç»“ï¼Œè¯·æ•´åˆä¸ºä¸€ä¸ªå®Œæ•´çš„æ€»ç»“ã€‚"},
            {"role": "user", "content": final_prompt},
        ],
        temperature=0.3,
    )
    
    return response.choices[0].message.content


def summarize_file(
    file_path: Path,
    output_dir: Optional[Path] = None,
    language: str = "zh",
    model: Optional[str] = None,
) -> Path:
    """
    æ€»ç»“æ–‡ä»¶å†…å®¹å¹¶ä¿å­˜
    
    Args:
        file_path: è¦æ€»ç»“çš„æ–‡ä»¶è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•
        language: è¾“å‡ºè¯­è¨€
        model: ä½¿ç”¨çš„æ¨¡å‹
    
    Returns:
        æ€»ç»“æ–‡ä»¶è·¯å¾„
    """
    output_dir = output_dir or OUTPUT_DIR
    
    # è¯»å–æ–‡ä»¶
    console.print(f"[cyan]ğŸ“– è¯»å–æ–‡ä»¶:[/cyan] {file_path.name}")
    text = file_path.read_text(encoding='utf-8')
    
    if not text.strip():
        raise ValueError("æ–‡ä»¶å†…å®¹ä¸ºç©º")
    
    console.print(f"[cyan]ğŸ“Š å†…å®¹é•¿åº¦:[/cyan] {len(text)} å­—ç¬¦")
    
    # ç”Ÿæˆæ€»ç»“
    summary = summarize_text(text, language=language, model=model)
    
    # ä¿å­˜æ€»ç»“
    output_path = output_dir / f"{file_path.stem}_summary.md"
    output_path.write_text(summary, encoding='utf-8')
    
    console.print(f"[green]âœ… æ€»ç»“å®Œæˆ:[/green] {output_path.name}")
    
    # åœ¨æ§åˆ¶å°æ˜¾ç¤ºæ€»ç»“
    console.print("\n" + "="*50)
    console.print(Markdown(summary))
    console.print("="*50 + "\n")
    
    return output_path


if __name__ == "__main__":
    # æµ‹è¯•
    test_text = """
    è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ã€‚ä»Šå¤©æˆ‘ä»¬è®¨è®ºäº†äººå·¥æ™ºèƒ½çš„å‘å±•è¶‹åŠ¿ã€‚
    ä¸»è¦æœ‰ä»¥ä¸‹å‡ ç‚¹ï¼š
    1. å¤§è¯­è¨€æ¨¡å‹æ­£åœ¨å¿«é€Ÿå‘å±•
    2. AI å·¥å…·æ­£åœ¨æ”¹å˜å·¥ä½œæ–¹å¼
    3. å®‰å…¨å’Œä¼¦ç†é—®é¢˜éœ€è¦å…³æ³¨
    """
    
    try:
        result = summarize_text(test_text)
        print(result)
    except ValueError as e:
        print(f"é”™è¯¯: {e}")

