"""
è¯­éŸ³è½¬å½•æ¨¡å—
ä½¿ç”¨ OpenAI Whisper è¿›è¡Œè¯­éŸ³è¯†åˆ«
"""
import re
from pathlib import Path
from typing import Optional
from rich.console import Console
from rich.progress import Progress, SpinnerColumn, TextColumn

from config import WHISPER_MODEL, OUTPUT_DIR

console = Console()


def parse_vtt_to_text(vtt_path: Path) -> str:
    """å°†VTTå­—å¹•æ–‡ä»¶è½¬æ¢ä¸ºçº¯æ–‡æœ¬"""
    content = vtt_path.read_text(encoding='utf-8')
    
    # ç§»é™¤VTTå¤´éƒ¨
    content = re.sub(r'^WEBVTT.*?\n\n', '', content, flags=re.DOTALL)
    
    # ç§»é™¤æ—¶é—´æˆ³è¡Œ
    content = re.sub(r'\d{2}:\d{2}:\d{2}\.\d{3} --> \d{2}:\d{2}:\d{2}\.\d{3}.*?\n', '', content)
    
    # ç§»é™¤ç©ºè¡Œå’Œæ ‡ç­¾
    content = re.sub(r'<[^>]+>', '', content)
    lines = [line.strip() for line in content.split('\n') if line.strip()]
    
    # å»é‡è¿ç»­ç›¸åŒçš„è¡Œï¼ˆè‡ªåŠ¨å­—å¹•å¸¸è§é—®é¢˜ï¼‰
    deduped = []
    for line in lines:
        if not deduped or line != deduped[-1]:
            deduped.append(line)
    
    return ' '.join(deduped)


def parse_srt_to_text(srt_path: Path) -> str:
    """å°†SRTå­—å¹•æ–‡ä»¶è½¬æ¢ä¸ºçº¯æ–‡æœ¬"""
    content = srt_path.read_text(encoding='utf-8')
    
    # ç§»é™¤åºå·è¡Œ
    content = re.sub(r'^\d+\s*$', '', content, flags=re.MULTILINE)
    
    # ç§»é™¤æ—¶é—´æˆ³è¡Œ
    content = re.sub(r'\d{2}:\d{2}:\d{2},\d{3} --> \d{2}:\d{2}:\d{2},\d{3}', '', content)
    
    # ç§»é™¤æ ‡ç­¾
    content = re.sub(r'<[^>]+>', '', content)
    lines = [line.strip() for line in content.split('\n') if line.strip()]
    
    # å»é‡
    deduped = []
    for line in lines:
        if not deduped or line != deduped[-1]:
            deduped.append(line)
    
    return ' '.join(deduped)


def subtitle_to_text(subtitle_path: Path) -> str:
    """å°†å­—å¹•æ–‡ä»¶è½¬æ¢ä¸ºçº¯æ–‡æœ¬"""
    suffix = subtitle_path.suffix.lower()
    
    if suffix == '.vtt':
        return parse_vtt_to_text(subtitle_path)
    elif suffix == '.srt':
        return parse_srt_to_text(subtitle_path)
    else:
        # å°è¯•ç›´æ¥è¯»å–
        return subtitle_path.read_text(encoding='utf-8')


def transcribe_audio(
    audio_path: Path,
    output_dir: Optional[Path] = None,
    model_name: Optional[str] = None,
    language: Optional[str] = None
) -> Path:
    """
    ä½¿ç”¨ Whisper è½¬å½•éŸ³é¢‘æ–‡ä»¶
    
    Args:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•
        model_name: Whisper æ¨¡å‹åç§° (tiny, base, small, medium, large)
        language: è¯­è¨€ä»£ç  (å¦‚ 'en', 'zh', 'ja' ç­‰)ï¼ŒNone è¡¨ç¤ºè‡ªåŠ¨æ£€æµ‹
    
    Returns:
        è½¬å½•æ–‡æœ¬æ–‡ä»¶è·¯å¾„
    """
    import whisper
    
    output_dir = output_dir or OUTPUT_DIR
    model_name = model_name or WHISPER_MODEL
    
    # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
    output_path = output_dir / f"{audio_path.stem}_transcript.txt"
    if output_path.exists():
        console.print(f"[yellow]â­ï¸  è½¬å½•æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡è½¬å½•:[/yellow] {output_path.name}")
        return output_path
    
    console.print(f"[yellow]ğŸ”„ æ­£åœ¨åŠ è½½ Whisper æ¨¡å‹ ({model_name})...[/yellow]")
    model = whisper.load_model(model_name)
    
    console.print("[yellow]ğŸ™ï¸  æ­£åœ¨è½¬å½•éŸ³é¢‘ (è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ)...[/yellow]")
    
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        console=console,
    ) as progress:
        task = progress.add_task("è½¬å½•ä¸­...", total=None)
        
        # è½¬å½•
        result = model.transcribe(
            str(audio_path),
            language=language,
            verbose=False,
        )
        
        progress.update(task, completed=True)
    
    # æ£€æµ‹åˆ°çš„è¯­è¨€
    detected_lang = result.get('language', 'unknown')
    console.print(f"[cyan]ğŸŒ æ£€æµ‹åˆ°è¯­è¨€:[/cyan] {detected_lang}")
    
    # ä¿å­˜å®Œæ•´æ–‡æœ¬
    text = result['text'].strip()
    # output_path å·²åœ¨å‡½æ•°å¼€å¤´å®šä¹‰ï¼Œè¿™é‡Œç›´æ¥ä½¿ç”¨
    output_path.write_text(text, encoding='utf-8')
    
    # ä¿å­˜å¸¦æ—¶é—´æˆ³çš„ç‰ˆæœ¬
    segments = result.get('segments', [])
    if segments:
        timestamped_output = output_dir / f"{audio_path.stem}_transcript_timestamped.txt"
        timestamped_lines = []
        for seg in segments:
            start = format_timestamp(seg['start'])
            end = format_timestamp(seg['end'])
            timestamped_lines.append(f"[{start} --> {end}] {seg['text'].strip()}")
        timestamped_output.write_text('\n'.join(timestamped_lines), encoding='utf-8')
        console.print(f"[green]âœ… å¸¦æ—¶é—´æˆ³è½¬å½•ä¿å­˜è‡³:[/green] {timestamped_output.name}")
    
    console.print(f"[green]âœ… è½¬å½•å®Œæˆ:[/green] {output_path.name}")
    
    return output_path


def format_timestamp(seconds: float) -> str:
    """å°†ç§’æ•°æ ¼å¼åŒ–ä¸ºæ—¶é—´æˆ³"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    
    if hours > 0:
        return f"{hours:02d}:{minutes:02d}:{secs:02d}"
    return f"{minutes:02d}:{secs:02d}"


def get_transcript(
    audio_path: Path,
    subtitle_path: Optional[Path] = None,
    output_dir: Optional[Path] = None,
    force_whisper: bool = False,
    language: Optional[str] = None,
) -> Path:
    """
    è·å–è½¬å½•æ–‡æœ¬
    
    ä¼˜å…ˆä½¿ç”¨å·²æœ‰å­—å¹•ï¼Œå¦‚æœæ²¡æœ‰æˆ–å¼ºåˆ¶ä½¿ç”¨ Whisper åˆ™è¿›è¡Œè¯­éŸ³è¯†åˆ«
    
    Args:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        subtitle_path: å­—å¹•æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        output_dir: è¾“å‡ºç›®å½•
        force_whisper: å¼ºåˆ¶ä½¿ç”¨ Whisper è½¬å½•
        language: è¯­è¨€ä»£ç 
    
    Returns:
        è½¬å½•æ–‡æœ¬æ–‡ä»¶è·¯å¾„
    """
    output_dir = output_dir or OUTPUT_DIR
    
    # å¦‚æœæœ‰å­—å¹•ä¸”ä¸å¼ºåˆ¶ä½¿ç”¨ Whisper
    if subtitle_path and subtitle_path.exists() and not force_whisper:
        console.print("[cyan]ğŸ“„ ä½¿ç”¨å·²ä¸‹è½½çš„å­—å¹•æ–‡ä»¶[/cyan]")
        text = subtitle_to_text(subtitle_path)
        
        output_path = output_dir / f"{audio_path.stem}_transcript.txt"
        output_path.write_text(text, encoding='utf-8')
        
        console.print(f"[green]âœ… å­—å¹•è½¬æ¢å®Œæˆ:[/green] {output_path.name}")
        return output_path
    
    # ä½¿ç”¨ Whisper è½¬å½•
    console.print("[cyan]ğŸ™ï¸  ä½¿ç”¨ Whisper è¿›è¡Œè¯­éŸ³è¯†åˆ«[/cyan]")
    return transcribe_audio(audio_path, output_dir, language=language)


if __name__ == "__main__":
    # æµ‹è¯•
    test_audio = Path("test.mp3")
    if test_audio.exists():
        result = transcribe_audio(test_audio)
        print(f"è½¬å½•ç»“æœ: {result}")

